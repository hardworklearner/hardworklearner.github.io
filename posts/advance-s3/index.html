<!DOCTYPE html>

<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en-US">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta
      name="theme-color"
      media="(prefers-color-scheme: light)"
      content="#f7f7f7"
    />
    <meta
      name="theme-color"
      media="(prefers-color-scheme: dark)"
      content="#1b1b1e"
    />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta
      name="apple-mobile-web-app-status-bar-style"
      content="black-translucent"
    />
    <meta
      name="viewport"
      content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
    />
    <!-- Setup Open Graph image -->

    <!-- Begin Jekyll SEO tag v2.8.0 -->
    <meta name="generator" content="Jekyll v4.4.1" />
    <meta property="og:title" content="Advance S3" />
    <meta name="author" content="Hardwork đẹp trai" />
    <meta property="og:locale" content="en_US" />
    <meta
      name="description"
      content="Advanced S3 S3 MFA-Delete MFA (multi factor authentication) forces user to generate a code on a device (ussually a mobile phone or hardware) before doing important operations on S3 To use MFA-Delete, enable Versioning on the S3 bucket You will need MFA to Permanently delete an object version suspend versioning on the bucket You won’t need MFA for enabling version listing deleted versions Only the bucket owner (root account) can enable/disable MFA delete MFA Delete currently can only S3 Default Encryption vs Bucket Policies One way to “force encryption” is to use bucket policy and refuse any API call to PUT an S3 object without encryption headers: Another way is to use the “default encryption” option in S3 Note: Bucket Policies are evaluated before “default encrytion” S3 Access Logs For audit purpose, you may want to log all access to S3 buckets Any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket That data can be analyzed using data analysis tools… Or Amazon Athena as we’ll see later in this section! The log format is at: https://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html S3 Access Logs: Warning Do not set your logging bucket to be the monitored bucket It will create a logging loop, and your bucket S3 Replication (CRR &amp; SRR) Must enable versioning in source and destination Cross Region Replication (CRR) Same Region Replication (SRR) Buckets can be in different accounts Copying is asynchronous Must give proper IAM permissions to S3 CRR - Use cases: compliance, lower latency access, replication across accounts SRR - Use cases: log aggregation, live replication between production and test accounts S3 Replication - Notes After activating, only new objects are replicated Optionally you can replicate existing object using S3 Batch Replication Replicates existing objects and objects that failed replication For Delete operations: Can replicate delete markers from source to target (optional setting) Deletions with a version ID are not replicated (to avoid malicious deletes) There is no “chaining” of replication If bucket I has replication into bucket 2, which has replication into bucket 3 The objects created in bucket I are not replicated to bucket 3 S3 Pre-Signed URLs Can generate pre-signed URLs using SDK or CLI For downloads (easy, can use the CLI) For uploads (harder, must use the SDK) Valid for a default of 3600 seconds, can change timeout with –expires-in [TIME_BY_SECONDS] argument Users given a pre-signed URL inherit the permissions of the person who generated the URL for GET / PUT Examples: Allow only logged-in users to download a premium video on your S3 bucket Allow an ever changing list of users to download files by generating URLs dynamically Allow temporarily a user to upload a file to a precise location in our bucket © Stephane Maarek S3 Storage Classes Amazon S3 Standard - General Purpose Amazon S3 Standard-Infrequent Access (IA) Amazon S3 One Zone-Infrequent Access Amazon S3 Glacier Instant Retrieval Amazon S3 Glacier Flexible Retrieval Amazon S3 Glacier Deep Archive Amazon S3 Intelligent Tiering Can move between classes manually or using S3 Lifecycle configurations S3 Durability and Availability Durability High durability (99.99999999%,   9’s) of objects across multiple AZ If you store 10000000 objects with Amazone S3, you can on average expect to incur a loss of a single object once every 10000 years Same for all storage classes Availability Measures how readily available a service is Varies depending on storage class Example S3 standard has 99.99% availability = not available 53 minutes a year S3 Standard – General Purpose 99,99% Availability Used for frequentlly accessed data Low latency and high throughput Sustain 2 concurent facility failures Use Cases: Big Data analytics, mobile &amp; gaming applications, content distribution… S3 Storage Classes – Infrequent Access For data that is less frequently accessed, but requires rapid access when needed Lower cost than S3 standard Amazon S3 standard-infrequent Access (S3 standard-IA) 99.99% availability Use cases: Disater recovery, backups Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) High durability (99.999999%) in a single AZ; data lost when AZ is destroyed 99.5 Availability Use Cases: Storing secondary backup copies of on-premises data, or data you can recreate Amazon S3 Glacier Storage Classes Low cost object storage meant for archiving / backup Pricing: price for storage + object retrieval cost Amazon S3 Glacier Instant Retrieval Milisecond retrieval, great for data accessed once a quarter Minimum storage duration of 90 days Amazon S3 Glacier Flexible Retrieval (formerly Amazon S3 Glacier) Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) – free Minimum storage duration of 90 days Amazon S3 Glacier Deep Archive – for long term storage Standard (12 hours), Bulk (48 hours) Minimum storage duration of 180 days S3 Intelligent-Tiering Small monthly monitoring and auto-tiering fee Moves objects automatically between Access Tier based on usage There are no retrieval charges in S3 Intelligent-Tiering Frequent Access tier (automatic): default tier Infrequent Access tier (automatic): objects not accessed for 30 days Archive Access tier (optional): configurable from 90 days to 700+ days Deep Archive Access tier (optional): config. from 180 days to 700+ days S3 Storage Classes Comparison S3 – Moving between storage classes You can transition objects between storage classes For infrequently accessed object, move them to STANDARD_IA For archive objects you don’t need in real time, GLACIER or DEEP-ARCHIVE moving objects can be automated using a lifecycle configuration S3 Lifecycle rules Transition actions: it defines when objects are transitioned to another storage class Move objects to Standard IA class 60 days after creation Move to Glacier for archiving after 6 months Expiration actions: configure oobjects to expire (delete) after some time Access log files can be set to delete after a 365 days Can be used to delete old versions of files (if versioning is enabled) Can be used to delete incomplete multi-part uploads Rules can be created for a certain prefix (ex - s3://mybucket/mp3/*) Rules can be created for a certain object tags (ex - Department Finance) S3 Lifecycle Rules – Scenario 1 Your application on Ec2 creates images thumbnails after profile photos are uploaded to Amazon S3. These thumbnails can be easily recreated, and only need to be kept for 45 days. The source images should be able to be immediately retrieved for these 45 days, and afterwards, the user can wait up to 6 hours. How would you design this? S3 source images can be on STANDARD, with a lifecycle configuration to expire them (delete them) after 45 days. S3 Lifecycle Rules – Scenario 2 A rule in your company states that you should be able to recover your deleted S3 objects immediately for 15 days, although this may happen rarely. After this time, and for up to 365 days, deleted objects should be recoverable withn 48 hours. You need to enable S3 versioning in order to have object versions, so that “deleted objects” are in fact hidden by a “delete marker” and can be recovered You can transition these “noncurrent versions” of the object to S3_IA You can transition afterwards these “noncurrent versions” to DEEP_ARCHIVE S3 Analytics – Storage Class Analysis You can setup S3 analytics to help determine when to transition objects from standard to standard_IA Does not work for ONEZONE_IA or GLACIER Report is updated daily Takes about 24h to 48h hours to first start Good first step to put together lifecycle rules (or improve them)! S3 Baseline performance Amazon S3 automatically scales to high request rates, latency 100-200ms Your application can achieve at least 3500 PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second per prefix in a bucket. There are no limits to the number of prefixes in a bucket. Example (object path =&gt; prefix): bucket/folder1/sub1/file =&gt; /folder1/sub1/ bucket/folder1/sub2/file =&gt; /folder1/sub2/ bucket/1/file =&gt; /1/ bucket/2/file =&gt; /2/ If you spread reads across all four prefixes evenly, you can achieve 22000 requests per second for GET and HEAD S3 – KMS Limitation If you use SSE-KMS, you may be impacted by the KMS limits When you upload, it call the GenerateDataKey KMS API When you download, it call the Decrypt KMS API Count towards the KMS qouta per second (5500, 10000. 30000 req/s based on region) You can request a qouta increase using Service Qoutas Console S3 Performance Multi-part upload recommended for files &gt; 100MB, must use for files &gt; 5GB Can help parallelize uploads (speed up transfers) S3 Transfer Acceleration Increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region. Compatible with multi-part upload S3 Performance - S3 Byte Range Fetches Parallelize GETs by requesting specific byte ranges Better resilience in case of failures Can be used to speed up downloads Can be used to retrieve only partial data (for example the head of a file) S3 Select &amp; Glacier Select Retrieve less data using SQL by performing server side filtering Can filter by rows &amp; columns (simple SQL statements) Less network transfer, less CPU cost client-side"
    />
    <meta
      property="og:description"
      content="Advanced S3 S3 MFA-Delete MFA (multi factor authentication) forces user to generate a code on a device (ussually a mobile phone or hardware) before doing important operations on S3 To use MFA-Delete, enable Versioning on the S3 bucket You will need MFA to Permanently delete an object version suspend versioning on the bucket You won’t need MFA for enabling version listing deleted versions Only the bucket owner (root account) can enable/disable MFA delete MFA Delete currently can only S3 Default Encryption vs Bucket Policies One way to “force encryption” is to use bucket policy and refuse any API call to PUT an S3 object without encryption headers: Another way is to use the “default encryption” option in S3 Note: Bucket Policies are evaluated before “default encrytion” S3 Access Logs For audit purpose, you may want to log all access to S3 buckets Any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket That data can be analyzed using data analysis tools… Or Amazon Athena as we’ll see later in this section! The log format is at: https://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html S3 Access Logs: Warning Do not set your logging bucket to be the monitored bucket It will create a logging loop, and your bucket S3 Replication (CRR &amp; SRR) Must enable versioning in source and destination Cross Region Replication (CRR) Same Region Replication (SRR) Buckets can be in different accounts Copying is asynchronous Must give proper IAM permissions to S3 CRR - Use cases: compliance, lower latency access, replication across accounts SRR - Use cases: log aggregation, live replication between production and test accounts S3 Replication - Notes After activating, only new objects are replicated Optionally you can replicate existing object using S3 Batch Replication Replicates existing objects and objects that failed replication For Delete operations: Can replicate delete markers from source to target (optional setting) Deletions with a version ID are not replicated (to avoid malicious deletes) There is no “chaining” of replication If bucket I has replication into bucket 2, which has replication into bucket 3 The objects created in bucket I are not replicated to bucket 3 S3 Pre-Signed URLs Can generate pre-signed URLs using SDK or CLI For downloads (easy, can use the CLI) For uploads (harder, must use the SDK) Valid for a default of 3600 seconds, can change timeout with –expires-in [TIME_BY_SECONDS] argument Users given a pre-signed URL inherit the permissions of the person who generated the URL for GET / PUT Examples: Allow only logged-in users to download a premium video on your S3 bucket Allow an ever changing list of users to download files by generating URLs dynamically Allow temporarily a user to upload a file to a precise location in our bucket © Stephane Maarek S3 Storage Classes Amazon S3 Standard - General Purpose Amazon S3 Standard-Infrequent Access (IA) Amazon S3 One Zone-Infrequent Access Amazon S3 Glacier Instant Retrieval Amazon S3 Glacier Flexible Retrieval Amazon S3 Glacier Deep Archive Amazon S3 Intelligent Tiering Can move between classes manually or using S3 Lifecycle configurations S3 Durability and Availability Durability High durability (99.99999999%,   9’s) of objects across multiple AZ If you store 10000000 objects with Amazone S3, you can on average expect to incur a loss of a single object once every 10000 years Same for all storage classes Availability Measures how readily available a service is Varies depending on storage class Example S3 standard has 99.99% availability = not available 53 minutes a year S3 Standard – General Purpose 99,99% Availability Used for frequentlly accessed data Low latency and high throughput Sustain 2 concurent facility failures Use Cases: Big Data analytics, mobile &amp; gaming applications, content distribution… S3 Storage Classes – Infrequent Access For data that is less frequently accessed, but requires rapid access when needed Lower cost than S3 standard Amazon S3 standard-infrequent Access (S3 standard-IA) 99.99% availability Use cases: Disater recovery, backups Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) High durability (99.999999%) in a single AZ; data lost when AZ is destroyed 99.5 Availability Use Cases: Storing secondary backup copies of on-premises data, or data you can recreate Amazon S3 Glacier Storage Classes Low cost object storage meant for archiving / backup Pricing: price for storage + object retrieval cost Amazon S3 Glacier Instant Retrieval Milisecond retrieval, great for data accessed once a quarter Minimum storage duration of 90 days Amazon S3 Glacier Flexible Retrieval (formerly Amazon S3 Glacier) Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) – free Minimum storage duration of 90 days Amazon S3 Glacier Deep Archive – for long term storage Standard (12 hours), Bulk (48 hours) Minimum storage duration of 180 days S3 Intelligent-Tiering Small monthly monitoring and auto-tiering fee Moves objects automatically between Access Tier based on usage There are no retrieval charges in S3 Intelligent-Tiering Frequent Access tier (automatic): default tier Infrequent Access tier (automatic): objects not accessed for 30 days Archive Access tier (optional): configurable from 90 days to 700+ days Deep Archive Access tier (optional): config. from 180 days to 700+ days S3 Storage Classes Comparison S3 – Moving between storage classes You can transition objects between storage classes For infrequently accessed object, move them to STANDARD_IA For archive objects you don’t need in real time, GLACIER or DEEP-ARCHIVE moving objects can be automated using a lifecycle configuration S3 Lifecycle rules Transition actions: it defines when objects are transitioned to another storage class Move objects to Standard IA class 60 days after creation Move to Glacier for archiving after 6 months Expiration actions: configure oobjects to expire (delete) after some time Access log files can be set to delete after a 365 days Can be used to delete old versions of files (if versioning is enabled) Can be used to delete incomplete multi-part uploads Rules can be created for a certain prefix (ex - s3://mybucket/mp3/*) Rules can be created for a certain object tags (ex - Department Finance) S3 Lifecycle Rules – Scenario 1 Your application on Ec2 creates images thumbnails after profile photos are uploaded to Amazon S3. These thumbnails can be easily recreated, and only need to be kept for 45 days. The source images should be able to be immediately retrieved for these 45 days, and afterwards, the user can wait up to 6 hours. How would you design this? S3 source images can be on STANDARD, with a lifecycle configuration to expire them (delete them) after 45 days. S3 Lifecycle Rules – Scenario 2 A rule in your company states that you should be able to recover your deleted S3 objects immediately for 15 days, although this may happen rarely. After this time, and for up to 365 days, deleted objects should be recoverable withn 48 hours. You need to enable S3 versioning in order to have object versions, so that “deleted objects” are in fact hidden by a “delete marker” and can be recovered You can transition these “noncurrent versions” of the object to S3_IA You can transition afterwards these “noncurrent versions” to DEEP_ARCHIVE S3 Analytics – Storage Class Analysis You can setup S3 analytics to help determine when to transition objects from standard to standard_IA Does not work for ONEZONE_IA or GLACIER Report is updated daily Takes about 24h to 48h hours to first start Good first step to put together lifecycle rules (or improve them)! S3 Baseline performance Amazon S3 automatically scales to high request rates, latency 100-200ms Your application can achieve at least 3500 PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second per prefix in a bucket. There are no limits to the number of prefixes in a bucket. Example (object path =&gt; prefix): bucket/folder1/sub1/file =&gt; /folder1/sub1/ bucket/folder1/sub2/file =&gt; /folder1/sub2/ bucket/1/file =&gt; /1/ bucket/2/file =&gt; /2/ If you spread reads across all four prefixes evenly, you can achieve 22000 requests per second for GET and HEAD S3 – KMS Limitation If you use SSE-KMS, you may be impacted by the KMS limits When you upload, it call the GenerateDataKey KMS API When you download, it call the Decrypt KMS API Count towards the KMS qouta per second (5500, 10000. 30000 req/s based on region) You can request a qouta increase using Service Qoutas Console S3 Performance Multi-part upload recommended for files &gt; 100MB, must use for files &gt; 5GB Can help parallelize uploads (speed up transfers) S3 Transfer Acceleration Increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region. Compatible with multi-part upload S3 Performance - S3 Byte Range Fetches Parallelize GETs by requesting specific byte ranges Better resilience in case of failures Can be used to speed up downloads Can be used to retrieve only partial data (for example the head of a file) S3 Select &amp; Glacier Select Retrieve less data using SQL by performing server side filtering Can filter by rows &amp; columns (simple SQL statements) Less network transfer, less CPU cost client-side"
    />
    <link
      rel="canonical"
      href="https://hardworklearner.github.io/posts/advance-s3/"
    />
    <meta
      property="og:url"
      content="https://hardworklearner.github.io/posts/advance-s3/"
    />
    <meta property="og:site_name" content="Programmer From Zero To Mountaint" />
    <meta property="og:type" content="article" />
    <meta
      property="article:published_time"
      content="2024-02-05T00:00:00+07:00"
    />
    <meta name="twitter:card" content="summary" />
    <meta property="twitter:title" content="Advance S3" />
    <meta name="twitter:site" content="@twitter_username" />
    <meta name="twitter:creator" content="@Hardwork đẹp trai" />
    <meta
      name="google-site-verification"
      content="google_meta_tag_verification"
    />
    <script type="application/ld+json">
      {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": { "@type": "Person", "name": "Hardwork đẹp trai" },
        "dateModified": "2024-02-05T00:00:00+07:00",
        "datePublished": "2024-02-05T00:00:00+07:00",
        "description": "Advanced S3 S3 MFA-Delete MFA (multi factor authentication) forces user to generate a code on a device (ussually a mobile phone or hardware) before doing important operations on S3 To use MFA-Delete, enable Versioning on the S3 bucket You will need MFA to Permanently delete an object version suspend versioning on the bucket You won’t need MFA for enabling version listing deleted versions Only the bucket owner (root account) can enable/disable MFA delete MFA Delete currently can only S3 Default Encryption vs Bucket Policies One way to “force encryption” is to use bucket policy and refuse any API call to PUT an S3 object without encryption headers: Another way is to use the “default encryption” option in S3 Note: Bucket Policies are evaluated before “default encrytion” S3 Access Logs For audit purpose, you may want to log all access to S3 buckets Any request made to S3, from any account, authorized or denied, will be logged into another S3 bucket That data can be analyzed using data analysis tools… Or Amazon Athena as we’ll see later in this section! The log format is at: https://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html S3 Access Logs: Warning Do not set your logging bucket to be the monitored bucket It will create a logging loop, and your bucket S3 Replication (CRR &amp; SRR) Must enable versioning in source and destination Cross Region Replication (CRR) Same Region Replication (SRR) Buckets can be in different accounts Copying is asynchronous Must give proper IAM permissions to S3 CRR - Use cases: compliance, lower latency access, replication across accounts SRR - Use cases: log aggregation, live replication between production and test accounts S3 Replication - Notes After activating, only new objects are replicated Optionally you can replicate existing object using S3 Batch Replication Replicates existing objects and objects that failed replication For Delete operations: Can replicate delete markers from source to target (optional setting) Deletions with a version ID are not replicated (to avoid malicious deletes) There is no “chaining” of replication If bucket I has replication into bucket 2, which has replication into bucket 3 The objects created in bucket I are not replicated to bucket 3 S3 Pre-Signed URLs Can generate pre-signed URLs using SDK or CLI For downloads (easy, can use the CLI) For uploads (harder, must use the SDK) Valid for a default of 3600 seconds, can change timeout with –expires-in [TIME_BY_SECONDS] argument Users given a pre-signed URL inherit the permissions of the person who generated the URL for GET / PUT Examples: Allow only logged-in users to download a premium video on your S3 bucket Allow an ever changing list of users to download files by generating URLs dynamically Allow temporarily a user to upload a file to a precise location in our bucket © Stephane Maarek S3 Storage Classes Amazon S3 Standard - General Purpose Amazon S3 Standard-Infrequent Access (IA) Amazon S3 One Zone-Infrequent Access Amazon S3 Glacier Instant Retrieval Amazon S3 Glacier Flexible Retrieval Amazon S3 Glacier Deep Archive Amazon S3 Intelligent Tiering Can move between classes manually or using S3 Lifecycle configurations S3 Durability and Availability Durability High durability (99.99999999%,   9’s) of objects across multiple AZ If you store 10000000 objects with Amazone S3, you can on average expect to incur a loss of a single object once every 10000 years Same for all storage classes Availability Measures how readily available a service is Varies depending on storage class Example S3 standard has 99.99% availability = not available 53 minutes a year S3 Standard – General Purpose 99,99% Availability Used for frequentlly accessed data Low latency and high throughput Sustain 2 concurent facility failures Use Cases: Big Data analytics, mobile &amp; gaming applications, content distribution… S3 Storage Classes – Infrequent Access For data that is less frequently accessed, but requires rapid access when needed Lower cost than S3 standard Amazon S3 standard-infrequent Access (S3 standard-IA) 99.99% availability Use cases: Disater recovery, backups Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) High durability (99.999999%) in a single AZ; data lost when AZ is destroyed 99.5 Availability Use Cases: Storing secondary backup copies of on-premises data, or data you can recreate Amazon S3 Glacier Storage Classes Low cost object storage meant for archiving / backup Pricing: price for storage + object retrieval cost Amazon S3 Glacier Instant Retrieval Milisecond retrieval, great for data accessed once a quarter Minimum storage duration of 90 days Amazon S3 Glacier Flexible Retrieval (formerly Amazon S3 Glacier) Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) – free Minimum storage duration of 90 days Amazon S3 Glacier Deep Archive – for long term storage Standard (12 hours), Bulk (48 hours) Minimum storage duration of 180 days S3 Intelligent-Tiering Small monthly monitoring and auto-tiering fee Moves objects automatically between Access Tier based on usage There are no retrieval charges in S3 Intelligent-Tiering Frequent Access tier (automatic): default tier Infrequent Access tier (automatic): objects not accessed for 30 days Archive Access tier (optional): configurable from 90 days to 700+ days Deep Archive Access tier (optional): config. from 180 days to 700+ days S3 Storage Classes Comparison S3 – Moving between storage classes You can transition objects between storage classes For infrequently accessed object, move them to STANDARD_IA For archive objects you don’t need in real time, GLACIER or DEEP-ARCHIVE moving objects can be automated using a lifecycle configuration S3 Lifecycle rules Transition actions: it defines when objects are transitioned to another storage class Move objects to Standard IA class 60 days after creation Move to Glacier for archiving after 6 months Expiration actions: configure oobjects to expire (delete) after some time Access log files can be set to delete after a 365 days Can be used to delete old versions of files (if versioning is enabled) Can be used to delete incomplete multi-part uploads Rules can be created for a certain prefix (ex - s3://mybucket/mp3/*) Rules can be created for a certain object tags (ex - Department Finance) S3 Lifecycle Rules – Scenario 1 Your application on Ec2 creates images thumbnails after profile photos are uploaded to Amazon S3. These thumbnails can be easily recreated, and only need to be kept for 45 days. The source images should be able to be immediately retrieved for these 45 days, and afterwards, the user can wait up to 6 hours. How would you design this? S3 source images can be on STANDARD, with a lifecycle configuration to expire them (delete them) after 45 days. S3 Lifecycle Rules – Scenario 2 A rule in your company states that you should be able to recover your deleted S3 objects immediately for 15 days, although this may happen rarely. After this time, and for up to 365 days, deleted objects should be recoverable withn 48 hours. You need to enable S3 versioning in order to have object versions, so that “deleted objects” are in fact hidden by a “delete marker” and can be recovered You can transition these “noncurrent versions” of the object to S3_IA You can transition afterwards these “noncurrent versions” to DEEP_ARCHIVE S3 Analytics – Storage Class Analysis You can setup S3 analytics to help determine when to transition objects from standard to standard_IA Does not work for ONEZONE_IA or GLACIER Report is updated daily Takes about 24h to 48h hours to first start Good first step to put together lifecycle rules (or improve them)! S3 Baseline performance Amazon S3 automatically scales to high request rates, latency 100-200ms Your application can achieve at least 3500 PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second per prefix in a bucket. There are no limits to the number of prefixes in a bucket. Example (object path =&gt; prefix): bucket/folder1/sub1/file =&gt; /folder1/sub1/ bucket/folder1/sub2/file =&gt; /folder1/sub2/ bucket/1/file =&gt; /1/ bucket/2/file =&gt; /2/ If you spread reads across all four prefixes evenly, you can achieve 22000 requests per second for GET and HEAD S3 – KMS Limitation If you use SSE-KMS, you may be impacted by the KMS limits When you upload, it call the GenerateDataKey KMS API When you download, it call the Decrypt KMS API Count towards the KMS qouta per second (5500, 10000. 30000 req/s based on region) You can request a qouta increase using Service Qoutas Console S3 Performance Multi-part upload recommended for files &gt; 100MB, must use for files &gt; 5GB Can help parallelize uploads (speed up transfers) S3 Transfer Acceleration Increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region. Compatible with multi-part upload S3 Performance - S3 Byte Range Fetches Parallelize GETs by requesting specific byte ranges Better resilience in case of failures Can be used to speed up downloads Can be used to retrieve only partial data (for example the head of a file) S3 Select &amp; Glacier Select Retrieve less data using SQL by performing server side filtering Can filter by rows &amp; columns (simple SQL statements) Less network transfer, less CPU cost client-side",
        "headline": "Advance S3",
        "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https://hardworklearner.github.io/posts/advance-s3/"
        },
        "url": "https://hardworklearner.github.io/posts/advance-s3/"
      }
    </script>
    <!-- End Jekyll SEO tag -->

    <!-- PWA cache settings -->
    <meta name="pwa-cache" content="true" />

    <title>Advance S3 | Programmer From Zero To Mountaint</title>

    <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->

    <link
      rel="apple-touch-icon"
      sizes="180x180"
      href="/assets/img/favicons/apple-touch-icon.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="32x32"
      href="/assets/img/favicons/favicon-32x32.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="16x16"
      href="/assets/img/favicons/favicon-16x16.png"
    />

    <link rel="manifest" href="/assets/img/favicons/site.webmanifest" />

    <link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" />
    <meta
      name="apple-mobile-web-app-title"
      content="Programmer From Zero To Mountaint"
    />
    <meta name="application-name" content="Programmer From Zero To Mountaint" />
    <meta name="msapplication-TileColor" content="#da532c" />
    <meta
      name="msapplication-config"
      content="/assets/img/favicons/browserconfig.xml"
    />
    <meta name="theme-color" content="#ffffff" />

    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="dns-prefetch" href="https://fonts.googleapis.com" />

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin />

    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="dns-prefetch" href="https://fonts.googleapis.com" />

    <link rel="preconnect" href="https://cdn.jsdelivr.net" />
    <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" />

    <link rel="preconnect" href="https://polyfill.io" />
    <link rel="dns-prefetch" href="https://polyfill.io" />

    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"
    />

    <!-- GA -->

    <!-- Bootstrap -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css"
    />

    <!-- Font Awesome -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"
    />

    <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css" />

    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/tocbot@4.25.0/dist/tocbot.min.css"
    />

    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"
    />

    <!-- Manific Popup -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"
    />

    <!-- JavaScript -->

    <!-- Switch the mode between dark and light. -->

    <script type="text/javascript">
      class ModeToggle {
        static get MODE_KEY() {
          return "mode";
        }
        static get MODE_ATTR() {
          return "data-mode";
        }
        static get DARK_MODE() {
          return "dark";
        }
        static get LIGHT_MODE() {
          return "light";
        }
        static get ID() {
          return "mode-toggle";
        }

        constructor() {
          if (this.hasMode) {
            if (this.isDarkMode) {
              if (!this.isSysDarkPrefer) {
                this.setDark();
              }
            } else {
              if (this.isSysDarkPrefer) {
                this.setLight();
              }
            }
          }

          let self = this;

          /* always follow the system prefers */
          this.sysDarkPrefers.addEventListener("change", () => {
            if (self.hasMode) {
              if (self.isDarkMode) {
                if (!self.isSysDarkPrefer) {
                  self.setDark();
                }
              } else {
                if (self.isSysDarkPrefer) {
                  self.setLight();
                }
              }

              self.clearMode();
            }

            self.notify();
          });
        } /* constructor() */

        get sysDarkPrefers() {
          return window.matchMedia("(prefers-color-scheme: dark)");
        }

        get isSysDarkPrefer() {
          return this.sysDarkPrefers.matches;
        }

        get isDarkMode() {
          return this.mode === ModeToggle.DARK_MODE;
        }

        get isLightMode() {
          return this.mode === ModeToggle.LIGHT_MODE;
        }

        get hasMode() {
          return this.mode != null;
        }

        get mode() {
          return sessionStorage.getItem(ModeToggle.MODE_KEY);
        }

        /* get the current mode on screen */
        get modeStatus() {
          if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
            return ModeToggle.DARK_MODE;
          } else {
            return ModeToggle.LIGHT_MODE;
          }
        }

        setDark() {
          document.documentElement.setAttribute(
            ModeToggle.MODE_ATTR,
            ModeToggle.DARK_MODE
          );
          sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
        }

        setLight() {
          document.documentElement.setAttribute(
            ModeToggle.MODE_ATTR,
            ModeToggle.LIGHT_MODE
          );
          sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
        }

        clearMode() {
          document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
          sessionStorage.removeItem(ModeToggle.MODE_KEY);
        }

        /* Notify another plugins that the theme mode has changed */
        notify() {
          window.postMessage(
            {
              direction: ModeToggle.ID,
              message: this.modeStatus,
            },
            "*"
          );
        }

        flipMode() {
          if (this.hasMode) {
            if (this.isSysDarkPrefer) {
              if (this.isLightMode) {
                this.clearMode();
              } else {
                this.setLight();
              }
            } else {
              if (this.isDarkMode) {
                this.clearMode();
              } else {
                this.setDark();
              }
            }
          } else {
            if (this.isSysDarkPrefer) {
              this.setLight();
            } else {
              this.setDark();
            }
          }

          this.notify();
        } /* flipMode() */
      } /* ModeToggle */

      const modeToggle = new ModeToggle();
    </script>

    <!-- A placeholder to allow defining custom metadata -->
  </head>

  <body>
    <!-- The Side Bar -->

    <aside
      aria-label="Sidebar"
      id="sidebar"
      class="d-flex flex-column align-items-end"
    >
      <header class="profile-wrapper">
        <a href="/" id="avatar" class="rounded-circle"
          ><img
            src="/assets/img/avatar.jpg"
            width="112"
            height="112"
            alt="avatar"
            onerror="this.style.display='none'"
        /></a>

        <h1 class="site-title">
          <a href="/">Programmer From Zero To Mountaint</a>
        </h1>
        <p class="site-subtitle fst-italic mb-0">Programmer blog</p>
      </header>
      <!-- .profile-wrapper -->

      <nav class="flex-column flex-grow-1 w-100 ps-0">
        <ul class="nav">
          <!-- home -->
          <li class="nav-item">
            <a href="/" class="nav-link">
              <i class="fa-fw fas fa-home"></i>
              <span>HOME</span>
            </a>
          </li>
          <!-- the real tabs -->

          <li class="nav-item">
            <a href="/categories/" class="nav-link">
              <i class="fa-fw fas fa-stream"></i>

              <span>CATEGORIES</span>
            </a>
          </li>
          <!-- .nav-item -->

          <li class="nav-item">
            <a href="/tags/" class="nav-link">
              <i class="fa-fw fas fa-tags"></i>

              <span>TAGS</span>
            </a>
          </li>
          <!-- .nav-item -->

          <li class="nav-item">
            <a href="/archives/" class="nav-link">
              <i class="fa-fw fas fa-archive"></i>

              <span>ARCHIVES</span>
            </a>
          </li>
          <!-- .nav-item -->

          <li class="nav-item">
            <a href="/about/" class="nav-link">
              <i class="fa-fw fas fa-info-circle"></i>

              <span>ABOUT</span>
            </a>
          </li>
          <!-- .nav-item -->

          <li class="nav-item">
            <a href="/portfoio/" class="nav-link">
              <i class="fa-fw fas fa-paper-plane"></i>

              <span>PORTFOLIO</span>
            </a>
          </li>
          <!-- .nav-item -->
        </ul>
      </nav>

      <div class="sidebar-bottom d-flex flex-wrap align-items-center w-100">
        <button type="button" class="mode-toggle btn" aria-label="Switch Mode">
          <i class="fas fa-adjust"></i>
        </button>

        <span class="icon-border"></span>

        <a
          href="https://github.com/hardworklearner"
          aria-label="github"
          target="_blank"
          rel="noopener noreferrer"
        >
          <i class="fab fa-github"></i>
        </a>

        <a
          href="https://twitter.com/twitter_username"
          aria-label="twitter"
          target="_blank"
          rel="noopener noreferrer"
        >
          <i class="fa-brands fa-x-twitter"></i>
        </a>

        <a
          href="javascript:location.href = 'mailto:' + ['huybinh.ad','gmail.com'].join('@')"
          aria-label="email"
        >
          <i class="fas fa-envelope"></i>
        </a>

        <a href="/feed.xml" aria-label="rss">
          <i class="fas fa-rss"></i>
        </a>

        <a
          href="https://www.linkedin.com/in/hardwork-nguyen-75312a7b/"
          aria-label="linkedin"
          target="_blank"
          rel="noopener noreferrer"
        >
          <i class="fab fa-linkedin"></i>
        </a>
      </div>
      <!-- .sidebar-bottom -->
    </aside>
    <!-- #sidebar -->

    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

        <header id="topbar-wrapper" aria-label="Top Bar">
          <div
            id="topbar"
            class="d-flex align-items-center justify-content-between px-lg-3 h-100"
          >
            <nav id="breadcrumb" aria-label="Breadcrumb">
              <span>
                <a href="/">Home</a>
              </span>

              <span>Advance S3</span>
            </nav>
            <!-- endof #breadcrumb -->

            <button type="button" id="sidebar-trigger" class="btn btn-link">
              <i class="fas fa-bars fa-fw"></i>
            </button>

            <div id="topbar-title">Post</div>

            <button type="button" id="search-trigger" class="btn btn-link">
              <i class="fas fa-search fa-fw"></i>
            </button>

            <search class="align-items-center ms-3 ms-lg-0">
              <i class="fas fa-search fa-fw"></i>
              <input
                class="form-control"
                id="search-input"
                type="search"
                aria-label="search"
                autocomplete="off"
                placeholder="Search..."
              />
            </search>
            <button
              type="button"
              class="btn btn-link text-decoration-none"
              id="search-cancel"
            >
              Cancel
            </button>
          </div>
        </header>

        <div class="row flex-grow-1">
          <main
            aria-label="Main Content"
            class="col-12 col-lg-11 col-xl-9 px-md-4"
          >
            <!-- Refactor the HTML structure -->

            <!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->

            <!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->

            <!-- Change the icon of checkbox -->

            <!-- Handle images -->

            <!-- take out classes -->

            <!-- lazy-load images -->

            <!-- make sure the `<img>` is wrapped by `<a>` -->

            <!-- create the image wrapper -->

            <!-- combine -->

            <!-- take out classes -->

            <!-- lazy-load images -->

            <!-- make sure the `<img>` is wrapped by `<a>` -->

            <!-- create the image wrapper -->

            <!-- combine -->

            <!-- take out classes -->

            <!-- lazy-load images -->

            <!-- make sure the `<img>` is wrapped by `<a>` -->

            <!-- create the image wrapper -->

            <!-- combine -->

            <!-- take out classes -->

            <!-- lazy-load images -->

            <!-- make sure the `<img>` is wrapped by `<a>` -->

            <!-- create the image wrapper -->

            <!-- combine -->

            <!-- Add header for code snippets -->

            <!-- Create heading anchors -->

            <!-- return -->

            <article class="px-1">
              <header>
                <h1 data-toc-skip>Advance S3</h1>

                <div class="post-meta text-muted">
                  <!-- published date -->
                  <span>
                    Posted
                    <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->

                    <time
                      data-ts="1707066000"
                      data-df="ll"
                      data-bs-toggle="tooltip"
                      data-bs-placement="bottom"
                    >
                      Feb 5, 2024
                    </time>
                  </span>

                  <!-- lastmod date -->

                  <div class="d-flex justify-content-between">
                    <!-- author(s) -->
                    <span>
                      By

                      <em>
                        <a href="https://twitter.com/username"
                          >Hardwork đẹp trai</a
                        >
                      </em>
                    </span>

                    <!-- read time -->
                    <!-- Calculate the post's reading time, and display the word count in tooltip -->

                    <!-- words per minute -->

                    <!-- return element -->
                    <span
                      class="readtime"
                      data-bs-toggle="tooltip"
                      data-bs-placement="bottom"
                      title="1490 words"
                    >
                      <em>8 min</em> read</span
                    >
                  </div>
                  <!-- .d-flex -->
                </div>
                <!-- .post-meta -->
              </header>

              <div class="content">
                <h1 id="advanced-s3">Advanced S3</h1>
                <h2 id="s3-mfa-delete">
                  <span class="me-2">S3 MFA-Delete</span
                  ><a href="#s3-mfa-delete" class="anchor text-muted"
                    ><i class="fas fa-hashtag"></i
                  ></a>
                </h2>
                <ul>
                  <li>
                    MFA (multi factor authentication) forces user to generate a
                    code on a device (ussually a mobile phone or hardware)
                    before doing important operations on S3
                  </li>
                  <li>To use MFA-Delete, enable Versioning on the S3 bucket</li>
                  <li>
                    You will need MFA to
                    <ul>
                      <li>Permanently delete an object version</li>
                      <li>suspend versioning on the bucket</li>
                    </ul>
                  </li>
                  <li>
                    You won’t need MFA for
                    <ul>
                      <li>enabling version</li>
                      <li>listing deleted versions</li>
                    </ul>
                  </li>
                  <li>
                    Only the bucket owner (root account) can enable/disable MFA
                    delete
                  </li>
                  <li>
                    MFA Delete currently can only
                    <h2 id="s3-default-encryption-vs-bucket-policies">
                      <span class="me-2"
                        >S3 Default Encryption vs Bucket Policies</span
                      ><a
                        href="#s3-default-encryption-vs-bucket-policies"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    One way to “force encryption” is to use bucket policy and
                    refuse any API call to PUT an S3 object without encryption
                    headers:
                  </li>
                  <li>
                    Another way is to use the “default encryption” option in S3
                  </li>
                  <li>
                    Note: Bucket Policies are evaluated before “default
                    encrytion”
                    <a
                      href="https://imgdb.net/storage/uploads/ac070c37691655f8796feed912be275de5ccb5c69daf3ee1acd0682b72d0a708.png"
                      class="popup img-link shimmer"
                      ><img
                        src="https://imgdb.net/storage/uploads/ac070c37691655f8796feed912be275de5ccb5c69daf3ee1acd0682b72d0a708.png"
                        alt=""
                        loading="lazy"
                    /></a>
                    <h2 id="s3-access-logs">
                      <span class="me-2">S3 Access Logs</span
                      ><a href="#s3-access-logs" class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    For audit purpose, you may want to log all access to S3
                    buckets
                  </li>
                  <li>
                    Any request made to S3, from any account, authorized or
                    denied, will be logged into another S3 bucket
                  </li>
                  <li>That data can be analyzed using data analysis tools…</li>
                  <li>Or Amazon Athena as we’ll see later in this section!</li>
                  <li>
                    The log format is at:
                    https://docs.aws.amazon.com/AmazonS3/latest/dev/LogFormat.html
                    <a
                      href="https://imgdb.net/storage/uploads/7b3a3dccb1fd49e3e2efd88a87b6c2d5695ec53d6b992f0db44af324afe00a53.png"
                      class="popup img-link shimmer"
                      ><img
                        src="https://imgdb.net/storage/uploads/7b3a3dccb1fd49e3e2efd88a87b6c2d5695ec53d6b992f0db44af324afe00a53.png"
                        alt=""
                        loading="lazy"
                    /></a>
                    <h2 id="s3-access-logs-warning">
                      <span class="me-2">S3 Access Logs: Warning</span
                      ><a
                        href="#s3-access-logs-warning"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    Do not set your logging bucket to be the monitored bucket
                  </li>
                  <li>
                    It will create a logging loop, and your bucket
                    <a
                      href="https://imgdb.net/storage/uploads/ac64eace72d2a244a83b854c511952e986e674521149bde10beabc5e6db5219c.png"
                      class="popup img-link shimmer"
                      ><img
                        src="https://imgdb.net/storage/uploads/ac64eace72d2a244a83b854c511952e986e674521149bde10beabc5e6db5219c.png"
                        alt=""
                        loading="lazy"
                    /></a>
                    <h2 id="s3-replication-crr--srr">
                      <span class="me-2">S3 Replication (CRR &amp; SRR)</span
                      ><a
                        href="#s3-replication-crr--srr"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>Must enable versioning in source and destination</li>
                  <li>Cross Region Replication (CRR)</li>
                  <li>Same Region Replication (SRR)</li>
                  <li>Buckets can be in different accounts</li>
                  <li>Copying is asynchronous</li>
                  <li>Must give proper IAM permissions to S3</li>
                  <li>
                    CRR - Use cases: compliance, lower latency access,
                    replication across accounts
                  </li>
                  <li>
                    SRR - Use cases: log aggregation, live replication between
                    production and test accounts
                    <h2 id="s3-replication---notes">
                      <span class="me-2">S3 Replication - Notes</span
                      ><a
                        href="#s3-replication---notes"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>After activating, only new objects are replicated</li>
                  <li>
                    Optionally you can replicate existing object using S3 Batch
                    Replication
                    <ul>
                      <li>
                        Replicates existing objects and objects that failed
                        replication
                      </li>
                    </ul>
                  </li>
                  <li>
                    For Delete operations:
                    <ul>
                      <li>
                        Can replicate delete markers from source to target
                        (optional setting)
                      </li>
                      <li>
                        Deletions with a version ID are not replicated (to avoid
                        malicious deletes)
                      </li>
                    </ul>
                  </li>
                  <li>
                    There is no “chaining” of replication
                    <ul>
                      <li>
                        If bucket I has replication into bucket 2, which has
                        replication into bucket 3
                      </li>
                      <li>
                        The objects created in bucket I are not replicated to
                        bucket 3
                        <h2 id="s3-pre-signed-urls">
                          <span class="me-2">S3 Pre-Signed URLs</span
                          ><a
                            href="#s3-pre-signed-urls"
                            class="anchor text-muted"
                            ><i class="fas fa-hashtag"></i
                          ></a>
                        </h2>
                      </li>
                    </ul>
                  </li>
                  <li>
                    Can generate pre-signed URLs using SDK or CLI
                    <ul>
                      <li>For downloads (easy, can use the CLI)</li>
                      <li>For uploads (harder, must use the SDK)</li>
                    </ul>
                  </li>
                  <li>
                    Valid for a default of 3600 seconds, can change timeout with
                    –expires-in [TIME_BY_SECONDS] argument
                  </li>
                  <li>
                    Users given a pre-signed URL inherit the permissions of the
                    person who generated the URL for GET / PUT
                  </li>
                  <li>
                    Examples:
                    <ul>
                      <li>
                        Allow only logged-in users to download a premium video
                        on your S3 bucket
                      </li>
                      <li>
                        Allow an ever changing list of users to download files
                        by generating URLs dynamically
                      </li>
                      <li>
                        Allow temporarily a user to upload a file to a precise
                        location in our bucket © Stephane Maarek
                        <h2 id="s3-storage-classes">
                          <span class="me-2">S3 Storage Classes</span
                          ><a
                            href="#s3-storage-classes"
                            class="anchor text-muted"
                            ><i class="fas fa-hashtag"></i
                          ></a>
                        </h2>
                      </li>
                    </ul>
                  </li>
                  <li>Amazon S3 Standard - General Purpose</li>
                  <li>Amazon S3 Standard-Infrequent Access (IA)</li>
                  <li>Amazon S3 One Zone-Infrequent Access</li>
                  <li>Amazon S3 Glacier Instant Retrieval</li>
                  <li>Amazon S3 Glacier Flexible Retrieval</li>
                  <li>Amazon S3 Glacier Deep Archive</li>
                  <li>Amazon S3 Intelligent Tiering</li>
                  <li>
                    Can move between classes manually or using S3 Lifecycle
                    configurations
                    <h2 id="s3-durability-and-availability">
                      <span class="me-2">S3 Durability and Availability</span
                      ><a
                        href="#s3-durability-and-availability"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    Durability
                    <ul>
                      <li>
                        <div class="table-wrapper">
                          <table>
                            <tbody>
                              <tr>
                                <td>High durability (99.99999999%,</td>
                                <td> </td>
                                <td>9’s) of objects across multiple AZ</td>
                              </tr>
                            </tbody>
                          </table>
                        </div>
                      </li>
                      <li>
                        If you store 10000000 objects with Amazone S3, you can
                        on average expect to incur a loss of a single object
                        once every 10000 years
                      </li>
                      <li>Same for all storage classes</li>
                    </ul>
                  </li>
                  <li>
                    Availability
                    <ul>
                      <li>Measures how readily available a service is</li>
                      <li>Varies depending on storage class</li>
                      <li>
                        Example S3 standard has 99.99% availability = not
                        available 53 minutes a year
                        <h2 id="s3-standard--general-purpose">
                          <span class="me-2">S3 Standard – General Purpose</span
                          ><a
                            href="#s3-standard--general-purpose"
                            class="anchor text-muted"
                            ><i class="fas fa-hashtag"></i
                          ></a>
                        </h2>
                      </li>
                    </ul>
                  </li>
                  <li>99,99% Availability</li>
                  <li>Used for frequentlly accessed data</li>
                  <li>Low latency and high throughput</li>
                  <li>Sustain 2 concurent facility failures</li>
                  <li>
                    Use Cases: Big Data analytics, mobile &amp; gaming
                    applications, content distribution…
                    <h2 id="s3-storage-classes--infrequent-access">
                      <span class="me-2"
                        >S3 Storage Classes – Infrequent Access</span
                      ><a
                        href="#s3-storage-classes--infrequent-access"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    For data that is less frequently accessed, but requires
                    rapid access when needed
                  </li>
                  <li>Lower cost than S3 standard</li>
                  <li>
                    Amazon S3 standard-infrequent Access (S3 standard-IA)
                    <ul>
                      <li>99.99% availability</li>
                      <li>Use cases: Disater recovery, backups</li>
                    </ul>
                  </li>
                  <li>
                    Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)
                    <ul>
                      <li>
                        High durability (99.999999%) in a single AZ; data lost
                        when AZ is destroyed
                      </li>
                      <li>99.5 Availability</li>
                      <li>
                        Use Cases: Storing secondary backup copies of
                        on-premises data, or data you can recreate
                        <h2 id="amazon-s3-glacier-storage-classes">
                          <span class="me-2"
                            >Amazon S3 Glacier Storage Classes</span
                          ><a
                            href="#amazon-s3-glacier-storage-classes"
                            class="anchor text-muted"
                            ><i class="fas fa-hashtag"></i
                          ></a>
                        </h2>
                      </li>
                    </ul>
                  </li>
                  <li>Low cost object storage meant for archiving / backup</li>
                  <li>Pricing: price for storage + object retrieval cost</li>
                  <li>
                    Amazon S3 Glacier Instant Retrieval
                    <ul>
                      <li>
                        Milisecond retrieval, great for data accessed once a
                        quarter
                      </li>
                      <li>Minimum storage duration of 90 days</li>
                    </ul>
                  </li>
                  <li>
                    Amazon S3 Glacier Flexible Retrieval (formerly Amazon S3
                    Glacier)
                    <ul>
                      <li>
                        Expedited (1 to 5 minutes), Standard (3 to 5 hours),
                        Bulk (5 to 12 hours) – free
                      </li>
                      <li>Minimum storage duration of 90 days</li>
                    </ul>
                  </li>
                  <li>
                    Amazon S3 Glacier Deep Archive – for long term storage
                    <ul>
                      <li>Standard (12 hours), Bulk (48 hours)</li>
                      <li>
                        Minimum storage duration of 180 days
                        <h2 id="s3-intelligent-tiering">
                          <span class="me-2">S3 Intelligent-Tiering</span
                          ><a
                            href="#s3-intelligent-tiering"
                            class="anchor text-muted"
                            ><i class="fas fa-hashtag"></i
                          ></a>
                        </h2>
                      </li>
                    </ul>
                  </li>
                  <li>Small monthly monitoring and auto-tiering fee</li>
                  <li>
                    Moves objects automatically between Access Tier based on
                    usage
                  </li>
                  <li>
                    There are no retrieval charges in S3 Intelligent-Tiering
                  </li>
                  <li>Frequent Access tier (automatic): default tier</li>
                  <li>
                    Infrequent Access tier (automatic): objects not accessed for
                    30 days
                  </li>
                  <li>
                    Archive Access tier (optional): configurable from 90 days to
                    700+ days
                  </li>
                  <li>
                    Deep Archive Access tier (optional): config. from 180 days
                    to 700+ days
                    <h2 id="s3-storage-classes-comparison">
                      <span class="me-2">S3 Storage Classes Comparison</span
                      ><a
                        href="#s3-storage-classes-comparison"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                    <p>
                      <a
                        href="https://imgdb.net/storage/uploads/675e3659d3b437df406f9bda761c703ea7b788cbea169acb3e5f7c3e98294185.png"
                        class="popup img-link shimmer"
                        ><img
                          src="https://imgdb.net/storage/uploads/675e3659d3b437df406f9bda761c703ea7b788cbea169acb3e5f7c3e98294185.png"
                          alt=""
                          loading="lazy"
                      /></a>
                    </p>
                    <h2 id="s3--moving-between-storage-classes">
                      <span class="me-2"
                        >S3 – Moving between storage classes</span
                      ><a
                        href="#s3--moving-between-storage-classes"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>You can transition objects between storage classes</li>
                  <li>
                    For infrequently accessed object, move them to STANDARD_IA
                  </li>
                  <li>
                    For archive objects you don’t need in real time, GLACIER or
                    DEEP-ARCHIVE
                  </li>
                  <li>
                    moving objects can be automated using a lifecycle
                    configuration
                    <h2 id="s3-lifecycle-rules">
                      <span class="me-2">S3 Lifecycle rules</span
                      ><a href="#s3-lifecycle-rules" class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    Transition actions: it defines when objects are transitioned
                    to another storage class
                    <ul>
                      <li>
                        Move objects to Standard IA class 60 days after creation
                      </li>
                      <li>Move to Glacier for archiving after 6 months</li>
                    </ul>
                  </li>
                  <li>
                    Expiration actions: configure oobjects to expire (delete)
                    after some time
                    <ul>
                      <li>
                        Access log files can be set to delete after a 365 days
                      </li>
                      <li>
                        Can be used to delete old versions of files (if
                        versioning is enabled)
                      </li>
                      <li>
                        Can be used to delete incomplete multi-part uploads
                      </li>
                    </ul>
                  </li>
                  <li>
                    Rules can be created for a certain prefix (ex -
                    s3://mybucket/mp3/*)
                  </li>
                  <li>
                    Rules can be created for a certain object tags (ex -
                    Department Finance)
                    <h2 id="s3-lifecycle-rules--scenario-1">
                      <span class="me-2">S3 Lifecycle Rules – Scenario 1</span
                      ><a
                        href="#s3-lifecycle-rules--scenario-1"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    Your application on Ec2 creates images thumbnails after
                    profile photos are uploaded to Amazon S3. These thumbnails
                    can be easily recreated, and only need to be kept for 45
                    days. The source images should be able to be immediately
                    retrieved for these 45 days, and afterwards, the user can
                    wait up to 6 hours. How would you design this?
                  </li>
                  <li>
                    S3 source images can be on STANDARD, with a lifecycle
                    configuration to expire them (delete them) after 45 days.
                    <h2 id="s3-lifecycle-rules--scenario-2">
                      <span class="me-2">S3 Lifecycle Rules – Scenario 2</span
                      ><a
                        href="#s3-lifecycle-rules--scenario-2"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    A rule in your company states that you should be able to
                    recover your deleted S3 objects immediately for 15 days,
                    although this may happen rarely. After this time, and for up
                    to 365 days, deleted objects should be recoverable withn 48
                    hours.
                  </li>
                  <li>
                    You need to enable S3 versioning in order to have object
                    versions, so that “deleted objects” are in fact hidden by a
                    “delete marker” and can be recovered
                  </li>
                  <li>
                    You can transition these “noncurrent versions” of the object
                    to S3_IA
                  </li>
                  <li>
                    You can transition afterwards these “noncurrent versions” to
                    DEEP_ARCHIVE
                    <h2 id="s3-analytics--storage-class-analysis">
                      <span class="me-2"
                        >S3 Analytics – Storage Class Analysis</span
                      ><a
                        href="#s3-analytics--storage-class-analysis"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    You can setup S3 analytics to help determine when to
                    transition objects from standard to standard_IA
                  </li>
                  <li>Does not work for ONEZONE_IA or GLACIER</li>
                  <li>Report is updated daily</li>
                  <li>Takes about 24h to 48h hours to first start</li>
                  <li>
                    Good first step to put together lifecycle rules (or improve
                    them)!
                    <h2 id="s3-baseline-performance">
                      <span class="me-2">S3 Baseline performance</span
                      ><a
                        href="#s3-baseline-performance"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    Amazon S3 automatically scales to high request rates,
                    latency 100-200ms
                  </li>
                  <li>
                    Your application can achieve at least 3500
                    PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second
                    per prefix in a bucket.
                  </li>
                  <li>
                    There are no limits to the number of prefixes in a bucket.
                  </li>
                  <li>
                    Example (object path =&gt; prefix):
                    <ul>
                      <li>bucket/folder1/sub1/file =&gt; /folder1/sub1/</li>
                      <li>bucket/folder1/sub2/file =&gt; /folder1/sub2/</li>
                      <li>bucket/1/file =&gt; /1/</li>
                      <li>bucket/2/file =&gt; /2/</li>
                    </ul>
                  </li>
                  <li>
                    If you spread reads across all four prefixes evenly, you can
                    achieve 22000 requests per second for GET and HEAD
                    <h2 id="s3--kms-limitation">
                      <span class="me-2">S3 – KMS Limitation</span
                      ><a href="#s3--kms-limitation" class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    If you use SSE-KMS, you may be impacted by the KMS limits
                  </li>
                  <li>When you upload, it call the GenerateDataKey KMS API</li>
                  <li>When you download, it call the Decrypt KMS API</li>
                  <li>
                    Count towards the KMS qouta per second (5500, 10000. 30000
                    req/s based on region)
                  </li>
                  <li>
                    You can request a qouta increase using Service Qoutas
                    Console
                    <h2 id="s3-performance">
                      <span class="me-2">S3 Performance</span
                      ><a href="#s3-performance" class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    Multi-part upload
                    <ul>
                      <li>
                        recommended for files &gt; 100MB, must use for files
                        &gt; 5GB
                      </li>
                      <li>Can help parallelize uploads (speed up transfers)</li>
                    </ul>
                  </li>
                  <li>
                    S3 Transfer Acceleration
                    <ul>
                      <li>
                        Increase transfer speed by transferring file to an AWS
                        edge location which will forward the data to the S3
                        bucket in the target region.
                      </li>
                      <li>
                        Compatible with multi-part upload
                        <h2 id="s3-performance---s3-byte-range-fetches">
                          <span class="me-2"
                            >S3 Performance - S3 Byte Range Fetches</span
                          ><a
                            href="#s3-performance---s3-byte-range-fetches"
                            class="anchor text-muted"
                            ><i class="fas fa-hashtag"></i
                          ></a>
                        </h2>
                      </li>
                    </ul>
                  </li>
                  <li>
                    <strong>Parallelize GETs</strong> by requesting
                    <strong>specific byte ranges</strong>
                  </li>
                  <li>Better resilience in case of failures</li>
                  <li>Can be used to speed up downloads</li>
                  <li>
                    Can be used to retrieve only partial data (for example the
                    head of a file)
                    <h2 id="s3-select--glacier-select">
                      <span class="me-2">S3 Select &amp; Glacier Select</span
                      ><a
                        href="#s3-select--glacier-select"
                        class="anchor text-muted"
                        ><i class="fas fa-hashtag"></i
                      ></a>
                    </h2>
                  </li>
                  <li>
                    Retrieve less data using SQL by performing server side
                    filtering
                  </li>
                  <li>
                    Can filter by rows &amp; columns (simple SQL statements)
                  </li>
                  <li>Less network transfer, less CPU cost client-side</li>
                </ul>
              </div>

              <div class="post-tail-wrapper text-muted">
                <!-- categories -->

                <div class="post-meta mb-3">
                  <i class="far fa-folder-open fa-fw me-1"></i>

                  <a href="/categories/fullstack/">Fullstack</a>,
                  <a href="/categories/architect/">Architect</a>,
                  <a href="/categories/aws/">AWS</a>
                </div>

                <!-- tags -->

                <div class="post-tags">
                  <i class="fa fa-tags fa-fw me-1"></i>

                  <a href="/tags/fullstack/" class="post-tag no-text-decoration"
                    >fullstack</a
                  >

                  <a
                    href="/tags/architecture/"
                    class="post-tag no-text-decoration"
                    >architecture</a
                  >

                  <a href="/tags/s3/" class="post-tag no-text-decoration">s3</a>

                  <a href="/tags/mfa/" class="post-tag no-text-decoration"
                    >MFA</a
                  >

                  <a href="/tags/kms/" class="post-tag no-text-decoration"
                    >KMS</a
                  >
                </div>

                <div
                  class="post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2"
                >
                  <div class="license-wrapper">
                    This post is licensed under
                    <a href="https://creativecommons.org/licenses/by/4.0/">
                      CC BY 4.0
                    </a>
                    by the author.
                  </div>

                  <!-- Post sharing snippet -->

                  <div class="share-wrapper d-flex align-items-center">
                    <span class="share-label text-muted">Share</span>
                    <span class="share-icons">
                      <a
                        href="https://twitter.com/AdHuybinh"
                        target="_blank"
                        rel="noopener"
                        data-bs-toggle="tooltip"
                        data-bs-placement="top"
                        title="Twitter"
                        aria-label="Twitter"
                      >
                        <i class="fa-fw fab fa-twitter"></i>
                      </a>

                      <a
                        href="https://www.facebook.com/alz.ailove"
                        target="_blank"
                        rel="noopener"
                        data-bs-toggle="tooltip"
                        data-bs-placement="top"
                        title="Facebook"
                        aria-label="Facebook"
                      >
                        <i class="fa-fw fab fa-facebook-square"></i>
                      </a>

                      <a
                        href="https://telegram.me/share?text=Advance%20S3%20-%20Programmer%20From%20Zero%20To%20Mountaint&url=https%3A%2F%2Fhardworklearner.github.io%2Fposts%2Fadvance-s3%2F"
                        target="_blank"
                        rel="noopener"
                        data-bs-toggle="tooltip"
                        data-bs-placement="top"
                        title="Telegram"
                        aria-label="Telegram"
                      >
                        <i class="fa-fw fab fa-telegram"></i>
                      </a>

                      <a
                        href="https://www.linkedin.com/in/hardwork-nguyen-75312a7b/"
                        target="_blank"
                        rel="noopener"
                        data-bs-toggle="tooltip"
                        data-bs-placement="top"
                        title="Linkedin"
                        aria-label="Linkedin"
                      >
                        <i class="fa-fw fab fa-linkedin"></i>
                      </a>

                      <button
                        id="copy-link"
                        aria-label="Copy link"
                        class="btn small"
                        data-bs-toggle="tooltip"
                        data-bs-placement="top"
                        title="Copy link"
                        data-title-succeed="Link copied successfully!"
                      >
                        <i class="fa-fw fas fa-link pe-none fs-6"></i>
                      </button>
                    </span>
                  </div>
                </div>
                <!-- .post-tail-bottom -->
              </div>
              <!-- div.post-tail-wrapper -->
            </article>
          </main>

          <!-- panel -->
          <aside
            aria-label="Panel"
            id="panel-wrapper"
            class="col-xl-3 ps-2 mb-5 text-muted"
          >
            <div class="access">
              <!-- Get 5 last posted/updated posts -->

              <section id="access-lastmod">
                <h2 class="panel-heading">Recently Updated</h2>
                <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
                  <li class="text-truncate lh-lg">
                    <a
                      href="/posts/laravel-react-adminlte-dashboard-project-and-todo-example/"
                      >Laravel React AdminLTE Dashboard Project and todo
                      example</a
                    >
                  </li>

                  <li class="text-truncate lh-lg">
                    <a href="/posts/aws-white-papers-and-architectures/"
                      >AWS White Papers and Architectures</a
                    >
                  </li>

                  <li class="text-truncate lh-lg">
                    <a href="/posts/virtual-private-cloud-vpc-part-2/"
                      >Virtual Private Cloud (VPC) part 2</a
                    >
                  </li>

                  <li class="text-truncate lh-lg">
                    <a href="/posts/aws-router-53/">AWS Router 53</a>
                  </li>

                  <li class="text-truncate lh-lg">
                    <a
                      href="/posts/aws-virtual-private-cloud-overview-vpc-part-1/"
                      >AWS Virtual Private Cloud Overview (VPC) part 1</a
                    >
                  </li>
                </ul>
              </section>
              <!-- #access-lastmod -->

              <!-- The trending tags list -->

              <section>
                <h2 class="panel-heading">Trending Tags</h2>
                <div class="d-flex flex-wrap mt-3 mb-1 me-3">
                  <a class="post-tag btn btn-outline-primary" href="/tags/aws/"
                    >aws</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/rails/"
                    >rails</a
                  >

                  <a class="post-tag btn btn-outline-primary" href="/tags/api/"
                    >api</a
                  >

                  <a class="post-tag btn btn-outline-primary" href="/tags/aws/"
                    >AWS</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/javascript/"
                    >javascript</a
                  >

                  <a class="post-tag btn btn-outline-primary" href="/tags/ruby/"
                    >ruby</a
                  >

                  <a class="post-tag btn btn-outline-primary" href="/tags/s3/"
                    >s3</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/architecture/"
                    >architecture</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/athena/"
                    >athena</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/aurora/"
                    >aurora</a
                  >
                </div>
              </section>
            </div>

            <section id="toc-wrapper" class="ps-0 pe-4">
              <h2 class="panel-heading ps-3 pt-2 mb-2">Contents</h2>
              <nav id="toc"></nav>
            </section>
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

            <!-- The total size of related posts -->

            <!-- An random integer that bigger than 0 -->

            <!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->

            <aside id="related-posts" aria-labelledby="related-label">
              <h3 class="mb-4" id="related-label">Further Reading</h3>
              <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
                <article class="col">
                  <a
                    href="/posts/aws-s3-and-aws-storage-gateway-services/"
                    class="post-preview card h-100"
                  >
                    <div class="card-body">
                      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->

                      <time data-ts="1707066000" data-df="ll">
                        Feb 5, 2024
                      </time>

                      <h4 class="pt-0 my-2">
                        AWS S3 and AWS Storage Gateway Services:
                      </h4>
                      <div class="text-muted">
                        <p>
                          Advannce S3 S3 MFA Delete MFA (mutil factor
                          authentication) forces uses to genenrate a code in a
                          device (usually a mobile phone or hardware) before
                          doing important operation on S3 To use MFA-D...
                        </p>
                      </div>
                    </div>
                  </a>
                </article>

                <article class="col">
                  <a
                    href="/posts/aws-security-encryption/"
                    class="post-preview card h-100"
                  >
                    <div class="card-body">
                      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->

                      <time data-ts="1707152400" data-df="ll">
                        Feb 6, 2024
                      </time>

                      <h4 class="pt-0 my-2">AWS Security & Encryption</h4>
                      <div class="text-muted">
                        <p>
                          AWS Security &amp;amp; Encryption KMS, Encryption SDK,
                          SSM Parameter Store Why encryption? Encryptio in
                          flight (SSL) Data is encrypted before sennding and
                          decrypted after receiving SSL certtificat...
                        </p>
                      </div>
                    </div>
                  </a>
                </article>

                <article class="col">
                  <a
                    href="/posts/aws-database-rds-aurora-elasticache-dynamodb-s3-athena-redshift-aws-glue-aws-neptune-elasticsearch/"
                    class="post-preview card h-100"
                  >
                    <div class="card-body">
                      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->

                      <time data-ts="1707152400" data-df="ll">
                        Feb 6, 2024
                      </time>

                      <h4 class="pt-0 my-2">
                        AWS Database: RDS, Aurora, ElastiCache, DynamoDB, S3,
                        Athena, Redshift, AWS Glue, AWS Neptune, ElasticSearch
                      </h4>
                      <div class="text-muted">
                        <p>
                          Databases Choosing the Right Database Read-heavy,
                          write heavy, or database workload? Throughput needs?
                          Will it change, does it need to scale or fluctuate
                          during the day? How much data to store...
                        </p>
                      </div>
                    </div>
                  </a>
                </article>
              </nav>
            </aside>
            <!-- #related-posts -->

            <!-- Navigation buttons at the bottom of the post. -->

            <nav
              class="post-navigation d-flex justify-content-between"
              aria-label="Post Navigation"
            >
              <a
                href="/posts/aws-api-gateway-lambda-serverless-and-services/"
                class="btn btn-outline-primary"
                aria-label="Older"
              >
                <p>AWS Api gateway, Lambda, Serverless, and Services part I</p>
              </a>

              <a
                href="/posts/aws-s3-and-aws-storage-gateway-services/"
                class="btn btn-outline-primary"
                aria-label="Newer"
              >
                <p>AWS S3 and AWS Storage Gateway Services:</p>
              </a>
            </nav>

            <!--  The comments switcher -->

            <!-- The Footer -->

            <footer
              aria-label="Site Info"
              class="d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3"
            >
              <p>
                ©
                <time>2025</time>

                <a href="https://twitter.com/username">Hardwork đẹp trai</a>.

                <span
                  data-bs-toggle="tooltip"
                  data-bs-placement="top"
                  title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
                  >Some rights reserved.</span
                >
              </p>

              <p>
                Using the
                <a
                  href="https://github.com/cotes2020/jekyll-theme-chirpy"
                  target="_blank"
                  rel="noopener"
                  >Chirpy</a
                >
                theme for
                <a href="https://jekyllrb.com" target="_blank" rel="noopener"
                  >Jekyll</a
                >.
              </p>
            </footer>
          </div>
        </div>

        <!-- The Search results -->

        <div
          id="search-result-wrapper"
          class="d-flex justify-content-center unloaded"
        >
          <div class="col-11 content">
            <div id="search-hints">
              <!-- The trending tags list -->

              <section>
                <h2 class="panel-heading">Trending Tags</h2>
                <div class="d-flex flex-wrap mt-3 mb-1 me-3">
                  <a class="post-tag btn btn-outline-primary" href="/tags/aws/"
                    >aws</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/rails/"
                    >rails</a
                  >

                  <a class="post-tag btn btn-outline-primary" href="/tags/api/"
                    >api</a
                  >

                  <a class="post-tag btn btn-outline-primary" href="/tags/aws/"
                    >AWS</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/javascript/"
                    >javascript</a
                  >

                  <a class="post-tag btn btn-outline-primary" href="/tags/ruby/"
                    >ruby</a
                  >

                  <a class="post-tag btn btn-outline-primary" href="/tags/s3/"
                    >s3</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/architecture/"
                    >architecture</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/athena/"
                    >athena</a
                  >

                  <a
                    class="post-tag btn btn-outline-primary"
                    href="/tags/aurora/"
                    >aurora</a
                  >
                </div>
              </section>
            </div>
            <div
              id="search-results"
              class="d-flex flex-wrap justify-content-center text-muted mt-3"
            ></div>
          </div>
        </div>
      </div>

      <aside aria-label="Scroll to Top">
        <button
          id="back-to-top"
          type="button"
          class="btn btn-lg btn-box-shadow"
        >
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask"></div>

    <aside
      id="notification"
      class="toast"
      role="alert"
      aria-live="assertive"
      aria-atomic="true"
      data-bs-animation="true"
      data-bs-autohide="false"
    >
      <div class="toast-header">
        <button
          type="button"
          class="btn-close ms-auto"
          data-bs-dismiss="toast"
          aria-label="Close"
        ></button>
      </div>
      <div class="toast-body text-center pt-0">
        <p class="px-2 mb-3">A new version of content is available.</p>
        <button type="button" class="btn btn-primary" aria-label="Update">
          Update
        </button>
      </div>
    </aside>

    <!-- JavaScripts -->

    <!-- JS selector for site. -->

    <!-- commons -->

    <!-- layout specified -->

    <!-- image lazy-loading & popup & clipboard -->

    <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.10/dayjs.min.js,npm/dayjs@1.11.10/locale/en.min.js,npm/dayjs@1.11.10/plugin/relativeTime.min.js,npm/dayjs@1.11.10/plugin/localizedFormat.min.js,npm/tocbot@4.25.0/dist/tocbot.min.js"></script>

    <script defer src="/assets/js/dist/post.min.js"></script>

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->

    <script>
      /* Note: dependent library will be loaded in `js-selector.html` */
      SimpleJekyllSearch({
        searchInput: document.getElementById("search-input"),
        resultsContainer: document.getElementById("search-results"),
        json: "/assets/js/data/search.json",
        searchResultTemplate:
          '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{snippet}</p>  </article>',
        noResultsText: '<p class="mt-5"></p>',
        templateMiddleware: function (prop, value, template) {
          if (prop === "categories") {
            if (value === "") {
              return `${value}`;
            } else {
              return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
            }
          }

          if (prop === "tags") {
            if (value === "") {
              return `${value}`;
            } else {
              return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
            }
          }
        },
      });
    </script>
  </body>
</html>
